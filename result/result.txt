{'$': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}
{'$': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}
==========================
Epoch: 010 // loss: 0.563856 // training accuracy: 0.562
테스트 정확도: 51.607%

tp:280
tn:9
fp:271
fn:0
precision : 0.5081669691470054
recall : 1.0



==========================
Epoch: 020 // loss: 0.079358 // training accuracy: 1.000
테스트 정확도: 89.643%

tp:242
tn:260
fp:20
fn:38
precision : 0.9236641221374046
recall : 0.8642857142857143



==========================
Epoch: 030 // loss: 0.102524 // training accuracy: 0.938
테스트 정확도: 91.607%

tp:242
tn:271
fp:9
fn:38
precision : 0.9641434262948207
recall : 0.8642857142857143



==========================
Epoch: 040 // loss: 0.155874 // training accuracy: 1.000
테스트 정확도: 93.571%

tp:278
tn:246
fp:34
fn:2
precision : 0.8910256410256411
recall : 0.9928571428571429



==========================
Epoch: 050 // loss: 0.181294 // training accuracy: 1.000
테스트 정확도: 95.357%

tp:278
tn:256
fp:24
fn:2
precision : 0.9205298013245033
recall : 0.9928571428571429



==========================
Epoch: 060 // loss: 0.196033 // training accuracy: 0.938
테스트 정확도: 95.179%

tp:267
tn:266
fp:14
fn:13
precision : 0.9501779359430605
recall : 0.9535714285714286



==========================
Epoch: 070 // loss: 0.254420 // training accuracy: 0.938
테스트 정확도: 93.571%

tp:265
tn:259
fp:21
fn:15
precision : 0.9265734265734266
recall : 0.9464285714285714



==========================
Epoch: 080 // loss: 0.386593 // training accuracy: 0.938
테스트 정확도: 93.214%

tp:279
tn:243
fp:37
fn:1
precision : 0.8829113924050633
recall : 0.9964285714285714



==========================
Epoch: 090 // loss: 0.017128 // training accuracy: 1.000
테스트 정확도: 94.464%

tp:272
tn:257
fp:23
fn:8
precision : 0.9220338983050848
recall : 0.9714285714285714



==========================
Epoch: 100 // loss: 0.009694 // training accuracy: 1.000
테스트 정확도: 86.964%

tp:220
tn:267
fp:13
fn:60
precision : 0.944206008583691
recall : 0.7857142857142857



==========================
Epoch: 110 // loss: 0.247797 // training accuracy: 0.938
테스트 정확도: 93.214%

tp:277
tn:245
fp:35
fn:3
precision : 0.8878205128205128
recall : 0.9892857142857143



==========================
Epoch: 120 // loss: 0.185954 // training accuracy: 0.938
테스트 정확도: 88.571%

tp:237
tn:259
fp:21
fn:43
precision : 0.9186046511627907
recall : 0.8464285714285714



==========================
Epoch: 130 // loss: 0.171957 // training accuracy: 0.938
테스트 정확도: 94.821%

tp:261
tn:270
fp:10
fn:19
precision : 0.9630996309963099
recall : 0.9321428571428572



==========================
Epoch: 140 // loss: 0.366806 // training accuracy: 0.938
테스트 정확도: 95.000%

tp:277
tn:255
fp:25
fn:3
precision : 0.9172185430463576
recall : 0.9892857142857143



==========================
Epoch: 150 // loss: 0.136245 // training accuracy: 0.875
테스트 정확도: 93.393%

tp:265
tn:258
fp:22
fn:15
precision : 0.9233449477351916
recall : 0.9464285714285714



==========================
Epoch: 160 // loss: 0.040635 // training accuracy: 1.000
테스트 정확도: 96.429%

tp:274
tn:266
fp:14
fn:6
precision : 0.9513888888888888
recall : 0.9785714285714285



==========================
Epoch: 170 // loss: 0.100548 // training accuracy: 1.000
테스트 정확도: 90.000%

tp:226
tn:278
fp:2
fn:54
precision : 0.9912280701754386
recall : 0.8071428571428572



==========================
Epoch: 180 // loss: 0.019551 // training accuracy: 1.000
테스트 정확도: 91.964%

tp:279
tn:236
fp:44
fn:1
precision : 0.8637770897832817
recall : 0.9964285714285714



==========================
Epoch: 190 // loss: 0.025945 // training accuracy: 1.000
테스트 정확도: 91.607%

tp:258
tn:255
fp:25
fn:22
precision : 0.911660777385159
recall : 0.9214285714285714



==========================
Epoch: 200 // loss: 0.572742 // training accuracy: 0.938
테스트 정확도: 95.000%

tp:260
tn:272
fp:8
fn:20
precision : 0.9701492537313433
recall : 0.9285714285714286



==========================
Epoch: 210 // loss: 0.008244 // training accuracy: 1.000
테스트 정확도: 95.714%

tp:265
tn:271
fp:9
fn:15
precision : 0.9671532846715328
recall : 0.9464285714285714



==========================
Epoch: 220 // loss: 0.304188 // training accuracy: 0.938
테스트 정확도: 96.964%

tp:279
tn:264
fp:16
fn:1
precision : 0.9457627118644067
recall : 0.9964285714285714



==========================
Epoch: 230 // loss: 0.052708 // training accuracy: 0.938
테스트 정확도: 92.857%

tp:280
tn:240
fp:40
fn:0
precision : 0.875
recall : 1.0



==========================
Epoch: 240 // loss: 0.099454 // training accuracy: 1.000
테스트 정확도: 97.321%

tp:270
tn:275
fp:5
fn:10
precision : 0.9818181818181818
recall : 0.9642857142857143



==========================
Epoch: 250 // loss: 0.004626 // training accuracy: 1.000
테스트 정확도: 97.679%

tp:274
tn:273
fp:7
fn:6
precision : 0.9750889679715302
recall : 0.9785714285714285



==========================
Epoch: 260 // loss: 0.033007 // training accuracy: 1.000
테스트 정확도: 94.821%

tp:256
tn:275
fp:5
fn:24
precision : 0.9808429118773946
recall : 0.9142857142857143



==========================
Epoch: 270 // loss: 0.263634 // training accuracy: 0.938
테스트 정확도: 96.429%

tp:263
tn:277
fp:3
fn:17
precision : 0.9887218045112782
recall : 0.9392857142857143



==========================
Epoch: 280 // loss: 0.031133 // training accuracy: 1.000
테스트 정확도: 96.964%

tp:273
tn:270
fp:10
fn:7
precision : 0.9646643109540636
recall : 0.975



==========================
Epoch: 290 // loss: 0.051489 // training accuracy: 1.000
테스트 정확도: 98.036%

tp:277
tn:272
fp:8
fn:3
precision : 0.9719298245614035
recall : 0.9892857142857143



==========================
Epoch: 300 // loss: 0.019323 // training accuracy: 1.000
테스트 정확도: 97.500%

tp:275
tn:271
fp:9
fn:5
precision : 0.9683098591549296
recall : 0.9821428571428571



==========================
Epoch: 310 // loss: 0.019312 // training accuracy: 1.000
테스트 정확도: 98.750%

tp:279
tn:274
fp:6
fn:1
precision : 0.9789473684210527
recall : 0.9964285714285714



==========================
Epoch: 320 // loss: 0.017292 // training accuracy: 1.000
테스트 정확도: 97.500%

tp:277
tn:269
fp:11
fn:3
precision : 0.9618055555555556
recall : 0.9892857142857143



==========================
Epoch: 330 // loss: 0.003495 // training accuracy: 1.000
테스트 정확도: 96.964%

tp:276
tn:267
fp:13
fn:4
precision : 0.9550173010380623
recall : 0.9857142857142858



==========================
Epoch: 340 // loss: 0.141458 // training accuracy: 0.938
테스트 정확도: 97.321%

tp:270
tn:275
fp:5
fn:10
precision : 0.9818181818181818
recall : 0.9642857142857143



==========================
Epoch: 350 // loss: 0.025842 // training accuracy: 1.000
테스트 정확도: 96.071%

tp:266
tn:272
fp:8
fn:14
precision : 0.9708029197080292
recall : 0.95



==========================
Epoch: 360 // loss: 0.009620 // training accuracy: 1.000
테스트 정확도: 98.393%

tp:278
tn:273
fp:7
fn:2
precision : 0.9754385964912281
recall : 0.9928571428571429



==========================
Epoch: 370 // loss: 0.007717 // training accuracy: 0.938
테스트 정확도: 96.964%

tp:277
tn:266
fp:14
fn:3
precision : 0.9518900343642611
recall : 0.9892857142857143



==========================
Epoch: 380 // loss: 0.036326 // training accuracy: 1.000
테스트 정확도: 95.000%

tp:253
tn:279
fp:1
fn:27
precision : 0.9960629921259843
recall : 0.9035714285714286



==========================
Epoch: 390 // loss: 0.085801 // training accuracy: 0.938
테스트 정확도: 98.750%

tp:279
tn:274
fp:6
fn:1
precision : 0.9789473684210527
recall : 0.9964285714285714



==========================
Epoch: 400 // loss: 0.061576 // training accuracy: 0.938
테스트 정확도: 91.429%

tp:280
tn:232
fp:48
fn:0
precision : 0.8536585365853658
recall : 1.0



==========================
Epoch: 410 // loss: 0.031178 // training accuracy: 1.000
테스트 정확도: 97.321%

tp:275
tn:270
fp:10
fn:5
precision : 0.9649122807017544
recall : 0.9821428571428571



==========================
Epoch: 420 // loss: 0.024733 // training accuracy: 0.938
테스트 정확도: 92.500%

tp:248
tn:270
fp:10
fn:32
precision : 0.9612403100775194
recall : 0.8857142857142857



==========================
Epoch: 430 // loss: 0.052627 // training accuracy: 1.000
테스트 정확도: 97.857%

tp:278
tn:270
fp:10
fn:2
precision : 0.9652777777777778
recall : 0.9928571428571429



==========================
Epoch: 440 // loss: 0.042082 // training accuracy: 1.000
테스트 정확도: 98.571%

tp:277
tn:275
fp:5
fn:3
precision : 0.9822695035460993
recall : 0.9892857142857143



==========================
Epoch: 450 // loss: 0.000208 // training accuracy: 0.938
테스트 정확도: 94.286%

tp:251
tn:277
fp:3
fn:29
precision : 0.9881889763779528
recall : 0.8964285714285715



==========================
Epoch: 460 // loss: 0.081813 // training accuracy: 1.000
테스트 정확도: 97.679%

tp:274
tn:273
fp:7
fn:6
precision : 0.9750889679715302
recall : 0.9785714285714285



==========================
Epoch: 470 // loss: 0.012468 // training accuracy: 1.000
테스트 정확도: 97.857%

tp:279
tn:269
fp:11
fn:1
precision : 0.9620689655172414
recall : 0.9964285714285714



==========================
Epoch: 480 // loss: 0.167980 // training accuracy: 0.938
테스트 정확도: 98.214%

tp:276
tn:274
fp:6
fn:4
precision : 0.9787234042553191
recall : 0.9857142857142858



==========================
Epoch: 490 // loss: 0.016405 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:277
tn:278
fp:2
fn:3
precision : 0.992831541218638
recall : 0.9892857142857143



==========================
Epoch: 500 // loss: 0.003269 // training accuracy: 1.000
테스트 정확도: 98.571%

tp:277
tn:275
fp:5
fn:3
precision : 0.9822695035460993
recall : 0.9892857142857143



==========================
Epoch: 510 // loss: 0.006594 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:278
tn:278
fp:2
fn:2
precision : 0.9928571428571429
recall : 0.9928571428571429



==========================
Epoch: 520 // loss: 0.001345 // training accuracy: 1.000
테스트 정확도: 98.571%

tp:272
tn:280
fp:0
fn:8
precision : 1.0
recall : 0.9714285714285714



==========================
Epoch: 530 // loss: 0.044130 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:277
tn:278
fp:2
fn:3
precision : 0.992831541218638
recall : 0.9892857142857143



==========================
Epoch: 540 // loss: 0.000196 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:276
tn:279
fp:1
fn:4
precision : 0.9963898916967509
recall : 0.9857142857142858



==========================
Epoch: 550 // loss: 0.001030 // training accuracy: 1.000
테스트 정확도: 97.857%

tp:270
tn:278
fp:2
fn:10
precision : 0.9926470588235294
recall : 0.9642857142857143



==========================
Epoch: 560 // loss: 0.002872 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:279
tn:275
fp:5
fn:1
precision : 0.9823943661971831
recall : 0.9964285714285714



==========================
Epoch: 570 // loss: 0.009945 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:279
tn:276
fp:4
fn:1
precision : 0.9858657243816255
recall : 0.9964285714285714



==========================
Epoch: 580 // loss: 0.002684 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:279
tn:277
fp:3
fn:1
precision : 0.9893617021276596
recall : 0.9964285714285714



==========================
Epoch: 590 // loss: 0.000041 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:279
tn:275
fp:5
fn:1
precision : 0.9823943661971831
recall : 0.9964285714285714



==========================
Epoch: 600 // loss: 0.027701 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:279
tn:278
fp:2
fn:1
precision : 0.9928825622775801
recall : 0.9964285714285714



==========================
Epoch: 610 // loss: 0.000018 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:277
tn:278
fp:2
fn:3
precision : 0.992831541218638
recall : 0.9892857142857143



==========================
Epoch: 620 // loss: 0.001390 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:277
tn:279
fp:1
fn:3
precision : 0.9964028776978417
recall : 0.9892857142857143



==========================
Epoch: 630 // loss: 0.000379 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 640 // loss: 0.003805 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:279
tn:278
fp:2
fn:1
precision : 0.9928825622775801
recall : 0.9964285714285714



==========================
Epoch: 650 // loss: 0.004082 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 660 // loss: 0.000009 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 670 // loss: 0.060295 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 680 // loss: 0.000001 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 690 // loss: 0.000419 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 700 // loss: 0.044143 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 710 // loss: 0.002483 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:279
tn:277
fp:3
fn:1
precision : 0.9893617021276596
recall : 0.9964285714285714



==========================
Epoch: 720 // loss: 0.006668 // training accuracy: 1.000
테스트 정확도: 96.786%

tp:263
tn:279
fp:1
fn:17
precision : 0.9962121212121212
recall : 0.9392857142857143



==========================
Epoch: 730 // loss: 0.020600 // training accuracy: 1.000
테스트 정확도: 98.571%

tp:279
tn:273
fp:7
fn:1
precision : 0.9755244755244755
recall : 0.9964285714285714



==========================
Epoch: 740 // loss: 0.070665 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:277
tn:279
fp:1
fn:3
precision : 0.9964028776978417
recall : 0.9892857142857143



==========================
Epoch: 750 // loss: 0.000508 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:277
tn:278
fp:2
fn:3
precision : 0.992831541218638
recall : 0.9892857142857143



==========================
Epoch: 760 // loss: 0.306012 // training accuracy: 0.938
테스트 정확도: 98.036%

tp:278
tn:271
fp:9
fn:2
precision : 0.9686411149825784
recall : 0.9928571428571429



==========================
Epoch: 770 // loss: 0.119137 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:277
tn:277
fp:3
fn:3
precision : 0.9892857142857143
recall : 0.9892857142857143



==========================
Epoch: 780 // loss: 0.170844 // training accuracy: 0.938
테스트 정확도: 92.679%

tp:279
tn:240
fp:40
fn:1
precision : 0.8746081504702194
recall : 0.9964285714285714



==========================
Epoch: 790 // loss: 0.054404 // training accuracy: 1.000
테스트 정확도: 91.607%

tp:259
tn:254
fp:26
fn:21
precision : 0.9087719298245615
recall : 0.925



==========================
Epoch: 800 // loss: 0.145618 // training accuracy: 0.875
테스트 정확도: 91.429%

tp:233
tn:279
fp:1
fn:47
precision : 0.9957264957264957
recall : 0.8321428571428572



==========================
Epoch: 810 // loss: 0.128428 // training accuracy: 0.938
테스트 정확도: 96.964%

tp:271
tn:272
fp:8
fn:9
precision : 0.9713261648745519
recall : 0.9678571428571429



==========================
Epoch: 820 // loss: 0.240931 // training accuracy: 1.000
테스트 정확도: 97.500%

tp:279
tn:267
fp:13
fn:1
precision : 0.9554794520547946
recall : 0.9964285714285714



==========================
Epoch: 830 // loss: 0.022075 // training accuracy: 0.938
테스트 정확도: 98.571%

tp:273
tn:279
fp:1
fn:7
precision : 0.9963503649635036
recall : 0.975



==========================
Epoch: 840 // loss: 0.026263 // training accuracy: 1.000
테스트 정확도: 98.750%

tp:273
tn:280
fp:0
fn:7
precision : 1.0
recall : 0.975



==========================
Epoch: 850 // loss: 0.000939 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 860 // loss: 0.006892 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 870 // loss: 0.014269 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:278
tn:279
fp:1
fn:2
precision : 0.996415770609319
recall : 0.9928571428571429



==========================
Epoch: 880 // loss: 0.222802 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 890 // loss: 0.029178 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:279
tn:277
fp:3
fn:1
precision : 0.9893617021276596
recall : 0.9964285714285714



==========================
Epoch: 900 // loss: 0.034668 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 910 // loss: 0.002111 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 920 // loss: 0.003770 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 930 // loss: 0.003927 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 940 // loss: 0.005956 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 950 // loss: 0.085081 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:279
tn:277
fp:3
fn:1
precision : 0.9893617021276596
recall : 0.9964285714285714



==========================
Epoch: 960 // loss: 0.002589 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 970 // loss: 0.076327 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 980 // loss: 0.006850 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 990 // loss: 0.001508 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:279
tn:275
fp:5
fn:1
precision : 0.9823943661971831
recall : 0.9964285714285714



==========================
Epoch: 1000 // loss: 0.002807 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1010 // loss: 0.004841 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1020 // loss: 0.019386 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1030 // loss: 0.000378 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1040 // loss: 0.000709 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1050 // loss: 0.002259 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1060 // loss: 0.002908 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:279
tn:275
fp:5
fn:1
precision : 0.9823943661971831
recall : 0.9964285714285714



==========================
Epoch: 1070 // loss: 0.001980 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1080 // loss: 0.003265 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1090 // loss: 0.002284 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1100 // loss: 0.002668 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1110 // loss: 0.002096 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1120 // loss: 0.000978 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1130 // loss: 0.000148 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1140 // loss: 0.002377 // training accuracy: 1.000
테스트 정확도: 98.393%

tp:271
tn:280
fp:0
fn:9
precision : 1.0
recall : 0.9678571428571429



==========================
Epoch: 1150 // loss: 0.019750 // training accuracy: 1.000
테스트 정확도: 96.786%

tp:279
tn:263
fp:17
fn:1
precision : 0.9425675675675675
recall : 0.9964285714285714



==========================
Epoch: 1160 // loss: 0.275733 // training accuracy: 0.938
테스트 정확도: 97.500%

tp:279
tn:267
fp:13
fn:1
precision : 0.9554794520547946
recall : 0.9964285714285714



==========================
Epoch: 1170 // loss: 0.006933 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:278
tn:279
fp:1
fn:2
precision : 0.996415770609319
recall : 0.9928571428571429



==========================
Epoch: 1180 // loss: 0.005458 // training accuracy: 1.000
테스트 정확도: 98.571%

tp:278
tn:274
fp:6
fn:2
precision : 0.9788732394366197
recall : 0.9928571428571429



==========================
Epoch: 1190 // loss: 0.010091 // training accuracy: 1.000
테스트 정확도: 98.750%

tp:277
tn:276
fp:4
fn:3
precision : 0.9857651245551602
recall : 0.9892857142857143



==========================
Epoch: 1200 // loss: 0.004451 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:278
tn:278
fp:2
fn:2
precision : 0.9928571428571429
recall : 0.9928571428571429



==========================
Epoch: 1210 // loss: 0.002994 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:278
tn:278
fp:2
fn:2
precision : 0.9928571428571429
recall : 0.9928571428571429



==========================
Epoch: 1220 // loss: 0.003019 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1230 // loss: 0.049517 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1240 // loss: 0.000204 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1250 // loss: 0.000250 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1260 // loss: 0.000125 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1270 // loss: 0.005755 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1280 // loss: 0.002574 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1290 // loss: 0.000099 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1300 // loss: 0.000823 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1310 // loss: 0.000092 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1320 // loss: 0.000134 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1330 // loss: 0.000087 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1340 // loss: 0.000076 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1350 // loss: 0.016383 // training accuracy: 1.000
테스트 정확도: 98.750%

tp:277
tn:276
fp:4
fn:3
precision : 0.9857651245551602
recall : 0.9892857142857143



==========================
Epoch: 1360 // loss: 0.014825 // training accuracy: 1.000
테스트 정확도: 97.857%

tp:269
tn:279
fp:1
fn:11
precision : 0.9962962962962963
recall : 0.9607142857142857



==========================
Epoch: 1370 // loss: 0.121780 // training accuracy: 1.000
테스트 정확도: 97.857%

tp:278
tn:270
fp:10
fn:2
precision : 0.9652777777777778
recall : 0.9928571428571429



==========================
Epoch: 1380 // loss: 0.010909 // training accuracy: 1.000
테스트 정확도: 98.571%

tp:274
tn:278
fp:2
fn:6
precision : 0.9927536231884058
recall : 0.9785714285714285



==========================
Epoch: 1390 // loss: 0.018875 // training accuracy: 0.938
테스트 정확도: 97.143%

tp:265
tn:279
fp:1
fn:15
precision : 0.9962406015037594
recall : 0.9464285714285714



==========================
Epoch: 1400 // loss: 0.184473 // training accuracy: 1.000
테스트 정확도: 97.679%

tp:269
tn:278
fp:2
fn:11
precision : 0.992619926199262
recall : 0.9607142857142857



==========================
Epoch: 1410 // loss: 0.005505 // training accuracy: 1.000
테스트 정확도: 98.750%

tp:277
tn:276
fp:4
fn:3
precision : 0.9857651245551602
recall : 0.9892857142857143



==========================
Epoch: 1420 // loss: 0.002355 // training accuracy: 1.000
테스트 정확도: 98.214%

tp:271
tn:279
fp:1
fn:9
precision : 0.9963235294117647
recall : 0.9678571428571429



==========================
Epoch: 1430 // loss: 0.013311 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:277
tn:279
fp:1
fn:3
precision : 0.9964028776978417
recall : 0.9892857142857143



==========================
Epoch: 1440 // loss: 0.023493 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1450 // loss: 0.004089 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:279
tn:278
fp:2
fn:1
precision : 0.9928825622775801
recall : 0.9964285714285714



==========================
Epoch: 1460 // loss: 0.002532 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1470 // loss: 0.000180 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1480 // loss: 0.001247 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1490 // loss: 0.002905 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1500 // loss: 0.006752 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1510 // loss: 0.024591 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1520 // loss: 0.000731 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1530 // loss: 0.002136 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1540 // loss: 0.000078 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1550 // loss: 0.015915 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1560 // loss: 0.001476 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1570 // loss: 0.000352 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1580 // loss: 0.001404 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1590 // loss: 0.000824 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1600 // loss: 0.000691 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1610 // loss: 0.000070 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1620 // loss: 0.001055 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1630 // loss: 0.001689 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1640 // loss: 0.000657 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1650 // loss: 0.000390 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1660 // loss: 0.000337 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1670 // loss: 0.014062 // training accuracy: 0.938
테스트 정확도: 98.571%

tp:272
tn:280
fp:0
fn:8
precision : 1.0
recall : 0.9714285714285714



==========================
Epoch: 1680 // loss: 0.000056 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:276
tn:280
fp:0
fn:4
precision : 1.0
recall : 0.9857142857142858



==========================
Epoch: 1690 // loss: 0.003197 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1700 // loss: 0.009307 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1710 // loss: 0.001715 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1720 // loss: 0.002126 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1730 // loss: 0.000040 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1740 // loss: 0.001471 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1750 // loss: 0.000035 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1760 // loss: 0.000075 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1770 // loss: 0.003779 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1780 // loss: 0.000108 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1790 // loss: 0.000664 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1800 // loss: 0.000111 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1810 // loss: 0.000038 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1820 // loss: 0.000030 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1830 // loss: 0.000279 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1840 // loss: 0.004372 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1850 // loss: 0.000157 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1860 // loss: 0.000386 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1870 // loss: 0.000046 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1880 // loss: 0.001652 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1890 // loss: 0.000027 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1900 // loss: 0.000023 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1910 // loss: 0.005660 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1920 // loss: 0.000303 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1930 // loss: 0.002224 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1940 // loss: 0.000056 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1950 // loss: 0.000040 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1960 // loss: 0.000027 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1970 // loss: 0.000024 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1980 // loss: 0.005188 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1990 // loss: 0.000022 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 2000 // loss: 0.002221 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



