{'$': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}
{'$': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}
==========================
Epoch: 010 // loss: 0.381654 // training accuracy: 1.000
테스트 정확도: 88.393%

tp:263
tn:232
fp:48
fn:17
precision : 0.8456591639871383
recall : 0.9392857142857143



==========================
Epoch: 020 // loss: 0.385234 // training accuracy: 0.938
테스트 정확도: 89.643%

tp:271
tn:231
fp:49
fn:9
precision : 0.846875
recall : 0.9678571428571429



==========================
Epoch: 030 // loss: 0.343516 // training accuracy: 0.938
테스트 정확도: 92.857%

tp:275
tn:245
fp:35
fn:5
precision : 0.8870967741935484
recall : 0.9821428571428571



==========================
Epoch: 040 // loss: 0.002189 // training accuracy: 1.000
테스트 정확도: 92.857%

tp:279
tn:241
fp:39
fn:1
precision : 0.8773584905660378
recall : 0.9964285714285714



==========================
Epoch: 050 // loss: 0.262643 // training accuracy: 0.875
테스트 정확도: 81.786%

tp:200
tn:258
fp:22
fn:80
precision : 0.9009009009009009
recall : 0.7142857142857143



==========================
Epoch: 060 // loss: 0.054092 // training accuracy: 1.000
테스트 정확도: 95.357%

tp:269
tn:265
fp:15
fn:11
precision : 0.9471830985915493
recall : 0.9607142857142857



==========================
Epoch: 070 // loss: 0.126006 // training accuracy: 1.000
테스트 정확도: 95.536%

tp:271
tn:264
fp:16
fn:9
precision : 0.9442508710801394
recall : 0.9678571428571429



==========================
Epoch: 080 // loss: 0.100219 // training accuracy: 0.938
테스트 정확도: 88.571%

tp:279
tn:217
fp:63
fn:1
precision : 0.8157894736842105
recall : 0.9964285714285714



==========================
Epoch: 090 // loss: 0.189668 // training accuracy: 0.938
테스트 정확도: 93.929%

tp:277
tn:249
fp:31
fn:3
precision : 0.8993506493506493
recall : 0.9892857142857143



==========================
Epoch: 100 // loss: 0.267282 // training accuracy: 0.938
테스트 정확도: 92.679%

tp:274
tn:245
fp:35
fn:6
precision : 0.8867313915857605
recall : 0.9785714285714285



==========================
Epoch: 110 // loss: 0.000295 // training accuracy: 1.000
테스트 정확도: 91.071%

tp:279
tn:231
fp:49
fn:1
precision : 0.850609756097561
recall : 0.9964285714285714



==========================
Epoch: 120 // loss: 0.129200 // training accuracy: 1.000
테스트 정확도: 91.429%

tp:243
tn:269
fp:11
fn:37
precision : 0.9566929133858267
recall : 0.8678571428571429



==========================
Epoch: 130 // loss: 0.044146 // training accuracy: 1.000
테스트 정확도: 96.429%

tp:275
tn:265
fp:15
fn:5
precision : 0.9482758620689655
recall : 0.9821428571428571



==========================
Epoch: 140 // loss: 0.043982 // training accuracy: 1.000
테스트 정확도: 95.714%

tp:271
tn:265
fp:15
fn:9
precision : 0.9475524475524476
recall : 0.9678571428571429



==========================
Epoch: 150 // loss: 0.012741 // training accuracy: 1.000
테스트 정확도: 94.821%

tp:279
tn:252
fp:28
fn:1
precision : 0.9087947882736156
recall : 0.9964285714285714



==========================
Epoch: 160 // loss: 0.251596 // training accuracy: 0.875
테스트 정확도: 91.071%

tp:236
tn:274
fp:6
fn:44
precision : 0.9752066115702479
recall : 0.8428571428571429



==========================
Epoch: 170 // loss: 0.048124 // training accuracy: 1.000
테스트 정확도: 96.429%

tp:277
tn:263
fp:17
fn:3
precision : 0.9421768707482994
recall : 0.9892857142857143



==========================
Epoch: 180 // loss: 0.290839 // training accuracy: 1.000
테스트 정확도: 96.786%

tp:277
tn:265
fp:15
fn:3
precision : 0.9486301369863014
recall : 0.9892857142857143



==========================
Epoch: 190 // loss: 0.191567 // training accuracy: 0.938
테스트 정확도: 97.143%

tp:275
tn:269
fp:11
fn:5
precision : 0.9615384615384616
recall : 0.9821428571428571



==========================
Epoch: 200 // loss: 0.058011 // training accuracy: 1.000
테스트 정확도: 96.071%

tp:264
tn:274
fp:6
fn:16
precision : 0.9777777777777777
recall : 0.9428571428571428



==========================
Epoch: 210 // loss: 0.013617 // training accuracy: 1.000
테스트 정확도: 96.071%

tp:275
tn:263
fp:17
fn:5
precision : 0.9417808219178082
recall : 0.9821428571428571



==========================
Epoch: 220 // loss: 0.004672 // training accuracy: 1.000
테스트 정확도: 95.893%

tp:276
tn:261
fp:19
fn:4
precision : 0.9355932203389831
recall : 0.9857142857142858



==========================
Epoch: 230 // loss: 0.228369 // training accuracy: 0.938
테스트 정확도: 94.464%

tp:249
tn:280
fp:0
fn:31
precision : 1.0
recall : 0.8892857142857142



==========================
Epoch: 240 // loss: 0.119695 // training accuracy: 0.938
테스트 정확도: 96.071%

tp:279
tn:259
fp:21
fn:1
precision : 0.93
recall : 0.9964285714285714



==========================
Epoch: 250 // loss: 0.057762 // training accuracy: 0.938
테스트 정확도: 97.679%

tp:275
tn:272
fp:8
fn:5
precision : 0.9717314487632509
recall : 0.9821428571428571



==========================
Epoch: 260 // loss: 0.146656 // training accuracy: 0.875
테스트 정확도: 96.429%

tp:267
tn:273
fp:7
fn:13
precision : 0.9744525547445255
recall : 0.9535714285714286



==========================
Epoch: 270 // loss: 0.010558 // training accuracy: 1.000
테스트 정확도: 96.607%

tp:265
tn:276
fp:4
fn:15
precision : 0.9851301115241635
recall : 0.9464285714285714



==========================
Epoch: 280 // loss: 0.012312 // training accuracy: 0.938
테스트 정확도: 96.786%

tp:277
tn:265
fp:15
fn:3
precision : 0.9486301369863014
recall : 0.9892857142857143



==========================
Epoch: 290 // loss: 0.015081 // training accuracy: 1.000
테스트 정확도: 96.429%

tp:278
tn:262
fp:18
fn:2
precision : 0.9391891891891891
recall : 0.9928571428571429



==========================
Epoch: 300 // loss: 0.899633 // training accuracy: 0.938
테스트 정확도: 95.179%

tp:267
tn:266
fp:14
fn:13
precision : 0.9501779359430605
recall : 0.9535714285714286



==========================
Epoch: 310 // loss: 0.056149 // training accuracy: 1.000
테스트 정확도: 98.214%

tp:276
tn:274
fp:6
fn:4
precision : 0.9787234042553191
recall : 0.9857142857142858



==========================
Epoch: 320 // loss: 0.001683 // training accuracy: 1.000
테스트 정확도: 96.786%

tp:272
tn:270
fp:10
fn:8
precision : 0.9645390070921985
recall : 0.9714285714285714



==========================
Epoch: 330 // loss: 0.088543 // training accuracy: 0.938
테스트 정확도: 96.250%

tp:265
tn:274
fp:6
fn:15
precision : 0.977859778597786
recall : 0.9464285714285714



==========================
Epoch: 340 // loss: 0.007351 // training accuracy: 1.000
테스트 정확도: 98.036%

tp:273
tn:276
fp:4
fn:7
precision : 0.9855595667870036
recall : 0.975



==========================
Epoch: 350 // loss: 0.003108 // training accuracy: 1.000
테스트 정확도: 96.786%

tp:278
tn:264
fp:16
fn:2
precision : 0.9455782312925171
recall : 0.9928571428571429



==========================
Epoch: 360 // loss: 0.004955 // training accuracy: 1.000
테스트 정확도: 98.214%

tp:277
tn:273
fp:7
fn:3
precision : 0.9753521126760564
recall : 0.9892857142857143



==========================
Epoch: 370 // loss: 0.203979 // training accuracy: 0.938
테스트 정확도: 95.893%

tp:258
tn:279
fp:1
fn:22
precision : 0.9961389961389961
recall : 0.9214285714285714



==========================
Epoch: 380 // loss: 0.025080 // training accuracy: 1.000
테스트 정확도: 98.571%

tp:276
tn:276
fp:4
fn:4
precision : 0.9857142857142858
recall : 0.9857142857142858



==========================
Epoch: 390 // loss: 0.015639 // training accuracy: 1.000
테스트 정확도: 98.214%

tp:277
tn:273
fp:7
fn:3
precision : 0.9753521126760564
recall : 0.9892857142857143



==========================
Epoch: 400 // loss: 0.114765 // training accuracy: 1.000
테스트 정확도: 97.857%

tp:271
tn:277
fp:3
fn:9
precision : 0.9890510948905109
recall : 0.9678571428571429



==========================
Epoch: 410 // loss: 0.003489 // training accuracy: 1.000
테스트 정확도: 98.036%

tp:271
tn:278
fp:2
fn:9
precision : 0.9926739926739927
recall : 0.9678571428571429



==========================
Epoch: 420 // loss: 0.003478 // training accuracy: 1.000
테스트 정확도: 97.500%

tp:276
tn:270
fp:10
fn:4
precision : 0.965034965034965
recall : 0.9857142857142858



==========================
Epoch: 430 // loss: 0.020197 // training accuracy: 1.000
테스트 정확도: 96.429%

tp:278
tn:262
fp:18
fn:2
precision : 0.9391891891891891
recall : 0.9928571428571429



==========================
Epoch: 440 // loss: 0.035774 // training accuracy: 1.000
테스트 정확도: 97.321%

tp:267
tn:278
fp:2
fn:13
precision : 0.9925650557620818
recall : 0.9535714285714286



==========================
Epoch: 450 // loss: 0.007659 // training accuracy: 1.000
테스트 정확도: 98.750%

tp:276
tn:277
fp:3
fn:4
precision : 0.989247311827957
recall : 0.9857142857142858



==========================
Epoch: 460 // loss: 0.034583 // training accuracy: 1.000
테스트 정확도: 98.036%

tp:277
tn:272
fp:8
fn:3
precision : 0.9719298245614035
recall : 0.9892857142857143



==========================
Epoch: 470 // loss: 0.025208 // training accuracy: 1.000
테스트 정확도: 98.571%

tp:275
tn:277
fp:3
fn:5
precision : 0.9892086330935251
recall : 0.9821428571428571



==========================
Epoch: 480 // loss: 0.001629 // training accuracy: 1.000
테스트 정확도: 96.964%

tp:263
tn:280
fp:0
fn:17
precision : 1.0
recall : 0.9392857142857143



==========================
Epoch: 490 // loss: 0.016695 // training accuracy: 1.000
테스트 정확도: 97.857%

tp:277
tn:271
fp:9
fn:3
precision : 0.9685314685314685
recall : 0.9892857142857143



==========================
Epoch: 500 // loss: 0.004778 // training accuracy: 1.000
테스트 정확도: 98.214%

tp:277
tn:273
fp:7
fn:3
precision : 0.9753521126760564
recall : 0.9892857142857143



==========================
Epoch: 510 // loss: 0.009624 // training accuracy: 1.000
테스트 정확도: 95.893%

tp:258
tn:279
fp:1
fn:22
precision : 0.9961389961389961
recall : 0.9214285714285714



==========================
Epoch: 520 // loss: 0.047867 // training accuracy: 1.000
테스트 정확도: 98.571%

tp:274
tn:278
fp:2
fn:6
precision : 0.9927536231884058
recall : 0.9785714285714285



==========================
Epoch: 530 // loss: 0.057953 // training accuracy: 0.938
테스트 정확도: 97.143%

tp:275
tn:269
fp:11
fn:5
precision : 0.9615384615384616
recall : 0.9821428571428571



==========================
Epoch: 540 // loss: 0.040936 // training accuracy: 1.000
테스트 정확도: 98.571%

tp:274
tn:278
fp:2
fn:6
precision : 0.9927536231884058
recall : 0.9785714285714285



==========================
Epoch: 550 // loss: 0.004405 // training accuracy: 1.000
테스트 정확도: 96.071%

tp:258
tn:280
fp:0
fn:22
precision : 1.0
recall : 0.9214285714285714



==========================
Epoch: 560 // loss: 0.000886 // training accuracy: 1.000
테스트 정확도: 98.393%

tp:277
tn:274
fp:6
fn:3
precision : 0.9787985865724381
recall : 0.9892857142857143



==========================
Epoch: 570 // loss: 0.000951 // training accuracy: 1.000
테스트 정확도: 98.393%

tp:278
tn:273
fp:7
fn:2
precision : 0.9754385964912281
recall : 0.9928571428571429



==========================
Epoch: 580 // loss: 0.021117 // training accuracy: 1.000
테스트 정확도: 97.857%

tp:268
tn:280
fp:0
fn:12
precision : 1.0
recall : 0.9571428571428572



==========================
Epoch: 590 // loss: 0.000988 // training accuracy: 1.000
테스트 정확도: 98.393%

tp:274
tn:277
fp:3
fn:6
precision : 0.9891696750902527
recall : 0.9785714285714285



==========================
Epoch: 600 // loss: 0.018357 // training accuracy: 1.000
테스트 정확도: 98.750%

tp:277
tn:276
fp:4
fn:3
precision : 0.9857651245551602
recall : 0.9892857142857143



==========================
Epoch: 610 // loss: 0.568576 // training accuracy: 0.938
테스트 정확도: 98.571%

tp:278
tn:274
fp:6
fn:2
precision : 0.9788732394366197
recall : 0.9928571428571429



==========================
Epoch: 620 // loss: 0.079505 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:276
tn:278
fp:2
fn:4
precision : 0.9928057553956835
recall : 0.9857142857142858



==========================
Epoch: 630 // loss: 0.000750 // training accuracy: 1.000
테스트 정확도: 98.571%

tp:274
tn:278
fp:2
fn:6
precision : 0.9927536231884058
recall : 0.9785714285714285



==========================
Epoch: 640 // loss: 0.000630 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:276
tn:278
fp:2
fn:4
precision : 0.9928057553956835
recall : 0.9857142857142858



==========================
Epoch: 650 // loss: 0.001873 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:276
tn:279
fp:1
fn:4
precision : 0.9963898916967509
recall : 0.9857142857142858



==========================
Epoch: 660 // loss: 0.015356 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:275
tn:279
fp:1
fn:5
precision : 0.9963768115942029
recall : 0.9821428571428571



==========================
Epoch: 670 // loss: 0.017060 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:276
tn:279
fp:1
fn:4
precision : 0.9963898916967509
recall : 0.9857142857142858



==========================
Epoch: 680 // loss: 0.018384 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:278
tn:278
fp:2
fn:2
precision : 0.9928571428571429
recall : 0.9928571428571429



==========================
Epoch: 690 // loss: 0.000077 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:277
tn:279
fp:1
fn:3
precision : 0.9964028776978417
recall : 0.9892857142857143



==========================
Epoch: 700 // loss: 0.000057 // training accuracy: 1.000
테스트 정확도: 98.750%

tp:273
tn:280
fp:0
fn:7
precision : 1.0
recall : 0.975



==========================
Epoch: 710 // loss: 0.002895 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:277
tn:279
fp:1
fn:3
precision : 0.9964028776978417
recall : 0.9892857142857143



==========================
Epoch: 720 // loss: 0.007023 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:277
tn:278
fp:2
fn:3
precision : 0.992831541218638
recall : 0.9892857142857143



==========================
Epoch: 730 // loss: 0.013719 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:277
tn:279
fp:1
fn:3
precision : 0.9964028776978417
recall : 0.9892857142857143



==========================
Epoch: 740 // loss: 0.008642 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 750 // loss: 0.003561 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 760 // loss: 0.000039 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 770 // loss: 0.000041 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:275
tn:280
fp:0
fn:5
precision : 1.0
recall : 0.9821428571428571



==========================
Epoch: 780 // loss: 0.000286 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 790 // loss: 0.000077 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:278
tn:279
fp:1
fn:2
precision : 0.996415770609319
recall : 0.9928571428571429



==========================
Epoch: 800 // loss: 0.006016 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:277
tn:279
fp:1
fn:3
precision : 0.9964028776978417
recall : 0.9892857142857143



==========================
Epoch: 810 // loss: 0.007389 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:277
tn:279
fp:1
fn:3
precision : 0.9964028776978417
recall : 0.9892857142857143



==========================
Epoch: 820 // loss: 0.001105 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:277
tn:279
fp:1
fn:3
precision : 0.9964028776978417
recall : 0.9892857142857143



==========================
Epoch: 830 // loss: 0.000030 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:277
tn:279
fp:1
fn:3
precision : 0.9964028776978417
recall : 0.9892857142857143



==========================
Epoch: 840 // loss: 0.000050 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 850 // loss: 0.000118 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:278
tn:279
fp:1
fn:2
precision : 0.996415770609319
recall : 0.9928571428571429



==========================
Epoch: 860 // loss: 0.000071 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:278
tn:279
fp:1
fn:2
precision : 0.996415770609319
recall : 0.9928571428571429



==========================
Epoch: 870 // loss: 0.000615 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 880 // loss: 0.001247 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 890 // loss: 0.000303 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:278
tn:279
fp:1
fn:2
precision : 0.996415770609319
recall : 0.9928571428571429



==========================
Epoch: 900 // loss: 0.000036 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 910 // loss: 0.000019 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 920 // loss: 0.000033 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 930 // loss: 0.000016 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 940 // loss: 0.000140 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 950 // loss: 0.000162 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 960 // loss: 0.000110 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 970 // loss: 0.000013 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 980 // loss: 0.000033 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 990 // loss: 0.000027 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1000 // loss: 0.000026 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1010 // loss: 0.000312 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1020 // loss: 0.000020 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1030 // loss: 0.006385 // training accuracy: 1.000
테스트 정확도: 98.036%

tp:279
tn:270
fp:10
fn:1
precision : 0.9653979238754326
recall : 0.9964285714285714



==========================
Epoch: 1040 // loss: 0.000068 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:277
tn:278
fp:2
fn:3
precision : 0.992831541218638
recall : 0.9892857142857143



==========================
Epoch: 1050 // loss: 0.007120 // training accuracy: 1.000
테스트 정확도: 95.536%

tp:277
tn:258
fp:22
fn:3
precision : 0.9264214046822743
recall : 0.9892857142857143



==========================
Epoch: 1060 // loss: 0.080099 // training accuracy: 1.000
테스트 정확도: 89.643%

tp:223
tn:279
fp:1
fn:57
precision : 0.9955357142857143
recall : 0.7964285714285714



==========================
Epoch: 1070 // loss: 0.007707 // training accuracy: 1.000
테스트 정확도: 97.321%

tp:275
tn:270
fp:10
fn:5
precision : 0.9649122807017544
recall : 0.9821428571428571



==========================
Epoch: 1080 // loss: 0.016487 // training accuracy: 1.000
테스트 정확도: 98.214%

tp:270
tn:280
fp:0
fn:10
precision : 1.0
recall : 0.9642857142857143



==========================
Epoch: 1090 // loss: 0.001865 // training accuracy: 1.000
테스트 정확도: 98.036%

tp:279
tn:270
fp:10
fn:1
precision : 0.9653979238754326
recall : 0.9964285714285714



==========================
Epoch: 1100 // loss: 0.055471 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:274
tn:280
fp:0
fn:6
precision : 1.0
recall : 0.9785714285714285



==========================
Epoch: 1110 // loss: 0.011178 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:275
tn:280
fp:0
fn:5
precision : 1.0
recall : 0.9821428571428571



==========================
Epoch: 1120 // loss: 0.000919 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:278
tn:279
fp:1
fn:2
precision : 0.996415770609319
recall : 0.9928571428571429



==========================
Epoch: 1130 // loss: 0.045828 // training accuracy: 1.000
테스트 정확도: 98.750%

tp:277
tn:276
fp:4
fn:3
precision : 0.9857651245551602
recall : 0.9892857142857143



==========================
Epoch: 1140 // loss: 0.000570 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:278
tn:276
fp:4
fn:2
precision : 0.9858156028368794
recall : 0.9928571428571429



==========================
Epoch: 1150 // loss: 0.236781 // training accuracy: 0.938
테스트 정확도: 97.500%

tp:267
tn:279
fp:1
fn:13
precision : 0.996268656716418
recall : 0.9535714285714286



==========================
Epoch: 1160 // loss: 0.039499 // training accuracy: 0.938
테스트 정확도: 97.679%

tp:268
tn:279
fp:1
fn:12
precision : 0.9962825278810409
recall : 0.9571428571428572



==========================
Epoch: 1170 // loss: 0.038415 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:279
tn:275
fp:5
fn:1
precision : 0.9823943661971831
recall : 0.9964285714285714



==========================
Epoch: 1180 // loss: 0.000174 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:275
tn:280
fp:0
fn:5
precision : 1.0
recall : 0.9821428571428571



==========================
Epoch: 1190 // loss: 0.000160 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:274
tn:280
fp:0
fn:6
precision : 1.0
recall : 0.9785714285714285



==========================
Epoch: 1200 // loss: 0.008965 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1210 // loss: 0.003214 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1220 // loss: 0.010610 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:275
tn:280
fp:0
fn:5
precision : 1.0
recall : 0.9821428571428571



==========================
Epoch: 1230 // loss: 0.004823 // training accuracy: 1.000
테스트 정확도: 98.750%

tp:273
tn:280
fp:0
fn:7
precision : 1.0
recall : 0.975



==========================
Epoch: 1240 // loss: 0.001494 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:278
tn:276
fp:4
fn:2
precision : 0.9858156028368794
recall : 0.9928571428571429



==========================
Epoch: 1250 // loss: 0.000326 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:278
tn:278
fp:2
fn:2
precision : 0.9928571428571429
recall : 0.9928571428571429



==========================
Epoch: 1260 // loss: 0.000073 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1270 // loss: 0.000054 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1280 // loss: 0.000034 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1290 // loss: 0.000172 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1300 // loss: 0.000041 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1310 // loss: 0.000126 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:278
tn:279
fp:1
fn:2
precision : 0.996415770609319
recall : 0.9928571428571429



==========================
Epoch: 1320 // loss: 0.000017 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1330 // loss: 0.000047 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1340 // loss: 0.000023 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1350 // loss: 0.000014 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1360 // loss: 0.000222 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1370 // loss: 0.000033 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1380 // loss: 0.000028 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1390 // loss: 0.000016 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1400 // loss: 0.000090 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:278
tn:279
fp:1
fn:2
precision : 0.996415770609319
recall : 0.9928571428571429



==========================
Epoch: 1410 // loss: 0.000014 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1420 // loss: 0.000007 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1430 // loss: 0.000429 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1440 // loss: 0.000029 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1450 // loss: 0.000009 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:278
tn:279
fp:1
fn:2
precision : 0.996415770609319
recall : 0.9928571428571429



==========================
Epoch: 1460 // loss: 0.000006 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1470 // loss: 0.000077 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1480 // loss: 0.000012 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:278
tn:279
fp:1
fn:2
precision : 0.996415770609319
recall : 0.9928571428571429



==========================
Epoch: 1490 // loss: 0.000006 // training accuracy: 1.000
테스트 정확도: 100.000%

tp:280
tn:280
fp:0
fn:0
precision : 1.0
recall : 1.0



==========================
Epoch: 1500 // loss: 0.000008 // training accuracy: 1.000
테스트 정확도: 99.821%

tp:279
tn:280
fp:0
fn:1
precision : 1.0
recall : 0.9964285714285714



==========================
Epoch: 1510 // loss: 0.000006 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1520 // loss: 0.000006 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1530 // loss: 0.000004 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:278
tn:280
fp:0
fn:2
precision : 1.0
recall : 0.9928571428571429



==========================
Epoch: 1540 // loss: 0.000004 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1550 // loss: 0.000110 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:280
tn:274
fp:6
fn:0
precision : 0.9790209790209791
recall : 1.0



==========================
Epoch: 1560 // loss: 0.448221 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1570 // loss: 0.216852 // training accuracy: 1.000
테스트 정확도: 97.321%

tp:277
tn:268
fp:12
fn:3
precision : 0.9584775086505191
recall : 0.9892857142857143



==========================
Epoch: 1580 // loss: 0.097158 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:277
tn:277
fp:3
fn:3
precision : 0.9892857142857143
recall : 0.9892857142857143



==========================
Epoch: 1590 // loss: 0.019669 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:276
tn:280
fp:0
fn:4
precision : 1.0
recall : 0.9857142857142858



==========================
Epoch: 1600 // loss: 0.141426 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:276
tn:280
fp:0
fn:4
precision : 1.0
recall : 0.9857142857142858



==========================
Epoch: 1610 // loss: 0.001165 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:277
tn:277
fp:3
fn:3
precision : 0.9892857142857143
recall : 0.9892857142857143



==========================
Epoch: 1620 // loss: 0.016202 // training accuracy: 1.000
테스트 정확도: 98.036%

tp:278
tn:271
fp:9
fn:2
precision : 0.9686411149825784
recall : 0.9928571428571429



==========================
Epoch: 1630 // loss: 0.185604 // training accuracy: 1.000
테스트 정확도: 96.607%

tp:261
tn:280
fp:0
fn:19
precision : 1.0
recall : 0.9321428571428572



==========================
Epoch: 1640 // loss: 0.233240 // training accuracy: 0.938
테스트 정확도: 96.786%

tp:262
tn:280
fp:0
fn:18
precision : 1.0
recall : 0.9357142857142857



==========================
Epoch: 1650 // loss: 0.189620 // training accuracy: 0.938
테스트 정확도: 97.679%

tp:267
tn:280
fp:0
fn:13
precision : 1.0
recall : 0.9535714285714286



==========================
Epoch: 1660 // loss: 0.144003 // training accuracy: 0.938
테스트 정확도: 97.857%

tp:268
tn:280
fp:0
fn:12
precision : 1.0
recall : 0.9571428571428572



==========================
Epoch: 1670 // loss: 0.000754 // training accuracy: 1.000
테스트 정확도: 97.857%

tp:268
tn:280
fp:0
fn:12
precision : 1.0
recall : 0.9571428571428572



==========================
Epoch: 1680 // loss: 0.019929 // training accuracy: 1.000
테스트 정확도: 97.857%

tp:268
tn:280
fp:0
fn:12
precision : 1.0
recall : 0.9571428571428572



==========================
Epoch: 1690 // loss: 0.009379 // training accuracy: 1.000
테스트 정확도: 97.857%

tp:268
tn:280
fp:0
fn:12
precision : 1.0
recall : 0.9571428571428572



==========================
Epoch: 1700 // loss: 0.000208 // training accuracy: 1.000
테스트 정확도: 97.857%

tp:268
tn:280
fp:0
fn:12
precision : 1.0
recall : 0.9571428571428572



==========================
Epoch: 1710 // loss: 0.116287 // training accuracy: 0.938
테스트 정확도: 98.036%

tp:269
tn:280
fp:0
fn:11
precision : 1.0
recall : 0.9607142857142857



==========================
Epoch: 1720 // loss: 0.086355 // training accuracy: 0.938
테스트 정확도: 97.857%

tp:268
tn:280
fp:0
fn:12
precision : 1.0
recall : 0.9571428571428572



==========================
Epoch: 1730 // loss: 0.054884 // training accuracy: 1.000
테스트 정확도: 97.857%

tp:273
tn:275
fp:5
fn:7
precision : 0.9820143884892086
recall : 0.975



==========================
Epoch: 1740 // loss: 0.000106 // training accuracy: 1.000
테스트 정확도: 97.679%

tp:270
tn:277
fp:3
fn:10
precision : 0.989010989010989
recall : 0.9642857142857143



==========================
Epoch: 1750 // loss: 0.005047 // training accuracy: 1.000
테스트 정확도: 98.571%

tp:273
tn:279
fp:1
fn:7
precision : 0.9963503649635036
recall : 0.975



==========================
Epoch: 1760 // loss: 0.000754 // training accuracy: 1.000
테스트 정확도: 98.750%

tp:280
tn:273
fp:7
fn:0
precision : 0.975609756097561
recall : 1.0



==========================
Epoch: 1770 // loss: 0.000107 // training accuracy: 1.000
테스트 정확도: 98.393%

tp:279
tn:272
fp:8
fn:1
precision : 0.9721254355400697
recall : 0.9964285714285714



==========================
Epoch: 1780 // loss: 0.061495 // training accuracy: 0.938
테스트 정확도: 97.857%

tp:268
tn:280
fp:0
fn:12
precision : 1.0
recall : 0.9571428571428572



==========================
Epoch: 1790 // loss: 0.060265 // training accuracy: 0.938
테스트 정확도: 97.857%

tp:268
tn:280
fp:0
fn:12
precision : 1.0
recall : 0.9571428571428572



==========================
Epoch: 1800 // loss: 0.096015 // training accuracy: 0.938
테스트 정확도: 97.679%

tp:278
tn:269
fp:11
fn:2
precision : 0.9619377162629758
recall : 0.9928571428571429



==========================
Epoch: 1810 // loss: 0.000232 // training accuracy: 1.000
테스트 정확도: 98.214%

tp:271
tn:279
fp:1
fn:9
precision : 0.9963235294117647
recall : 0.9678571428571429



==========================
Epoch: 1820 // loss: 0.000113 // training accuracy: 1.000
테스트 정확도: 98.393%

tp:271
tn:280
fp:0
fn:9
precision : 1.0
recall : 0.9678571428571429



==========================
Epoch: 1830 // loss: 0.000164 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:276
tn:278
fp:2
fn:4
precision : 0.9928057553956835
recall : 0.9857142857142858



==========================
Epoch: 1840 // loss: 0.004100 // training accuracy: 1.000
테스트 정확도: 98.393%

tp:276
tn:275
fp:5
fn:4
precision : 0.9822064056939501
recall : 0.9857142857142858



==========================
Epoch: 1850 // loss: 0.035804 // training accuracy: 1.000
테스트 정확도: 98.571%

tp:272
tn:280
fp:0
fn:8
precision : 1.0
recall : 0.9714285714285714



==========================
Epoch: 1860 // loss: 0.113371 // training accuracy: 0.938
테스트 정확도: 98.393%

tp:272
tn:279
fp:1
fn:8
precision : 0.9963369963369964
recall : 0.9714285714285714



==========================
Epoch: 1870 // loss: 0.470069 // training accuracy: 0.938
테스트 정확도: 99.107%

tp:278
tn:277
fp:3
fn:2
precision : 0.9893238434163701
recall : 0.9928571428571429



==========================
Epoch: 1880 // loss: 0.006478 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:277
tn:278
fp:2
fn:3
precision : 0.992831541218638
recall : 0.9892857142857143



==========================
Epoch: 1890 // loss: 0.003220 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:276
tn:278
fp:2
fn:4
precision : 0.9928057553956835
recall : 0.9857142857142858



==========================
Epoch: 1900 // loss: 0.004314 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:278
tn:277
fp:3
fn:2
precision : 0.9893238434163701
recall : 0.9928571428571429



==========================
Epoch: 1910 // loss: 0.002633 // training accuracy: 1.000
테스트 정확도: 98.571%

tp:278
tn:274
fp:6
fn:2
precision : 0.9788732394366197
recall : 0.9928571428571429



==========================
Epoch: 1920 // loss: 0.021684 // training accuracy: 1.000
테스트 정확도: 99.286%

tp:277
tn:279
fp:1
fn:3
precision : 0.9964028776978417
recall : 0.9892857142857143



==========================
Epoch: 1930 // loss: 0.056263 // training accuracy: 1.000
테스트 정확도: 98.929%

tp:275
tn:279
fp:1
fn:5
precision : 0.9963768115942029
recall : 0.9821428571428571



==========================
Epoch: 1940 // loss: 0.170072 // training accuracy: 0.938
테스트 정확도: 98.929%

tp:278
tn:276
fp:4
fn:2
precision : 0.9858156028368794
recall : 0.9928571428571429



==========================
Epoch: 1950 // loss: 0.002338 // training accuracy: 1.000
테스트 정확도: 99.643%

tp:279
tn:279
fp:1
fn:1
precision : 0.9964285714285714
recall : 0.9964285714285714



==========================
Epoch: 1960 // loss: 0.004463 // training accuracy: 0.938
테스트 정확도: 97.321%

tp:267
tn:278
fp:2
fn:13
precision : 0.9925650557620818
recall : 0.9535714285714286



==========================
Epoch: 1970 // loss: 0.001638 // training accuracy: 1.000
테스트 정확도: 99.107%

tp:277
tn:278
fp:2
fn:3
precision : 0.992831541218638
recall : 0.9892857142857143



==========================
Epoch: 1980 // loss: 0.002147 // training accuracy: 1.000
테스트 정확도: 99.464%

tp:277
tn:280
fp:0
fn:3
precision : 1.0
recall : 0.9892857142857143



==========================
Epoch: 1990 // loss: 0.113745 // training accuracy: 1.000
테스트 정확도: 95.893%

tp:257
tn:280
fp:0
fn:23
precision : 1.0
recall : 0.9178571428571428



==========================
Epoch: 2000 // loss: 0.109744 // training accuracy: 0.938
테스트 정확도: 98.571%

tp:272
tn:280
fp:0
fn:8
precision : 1.0
recall : 0.9714285714285714



